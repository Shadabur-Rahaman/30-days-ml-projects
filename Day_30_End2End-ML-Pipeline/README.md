# ğŸ§  Day 30 of #30DaysMLProjects: End-to-End Machine Learning Pipeline

Welcome to the final project of my 30 Days of ML Projects challenge! This project demonstrates the creation of a complete end-to-end machine learning pipeline, encapsulating the full workflow from data ingestion to deployment-ready model packaging.

---

## ğŸš€ Project Highlights

- **Data Source**: Utilized real-world datasets to simulate production scenarios.
- **Pipeline Components**:
  - Data Loading & Preprocessing
  - Feature Engineering
  - Model Selection & Training
  - Hyperparameter Tuning
  - Evaluation (Accuracy, Precision, Recall, F1)
  - Serialization with `joblib`
  - Deployment-ready structure

---

## ğŸ§° Technologies Used

- Python (Pandas, Scikit-learn, NumPy, Matplotlib, Seaborn)
- Jupyter Notebook
- Joblib
- Clean, modular pipeline architecture

---

## ğŸ“ Folder Structure
```bash
.
â”œâ”€â”€ api
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ __pycache__
â”‚       â””â”€â”€ main.cpython-311.pyc
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ .ipynb_checkpoints
â”‚   â”œâ”€â”€ iris_raw.csv
â”‚   â”œâ”€â”€ X_test.csv
â”‚   â”œâ”€â”€ X_train.csv
â”‚   â”œâ”€â”€ y_test.csv
â”‚   â””â”€â”€ y_train.csv
â”œâ”€â”€ github
â”‚   â”œâ”€â”€ .ipynb_checkpoints
â”‚   â””â”€â”€ workflows
â”‚       â””â”€â”€ ml-pipeline.yml
â”œâ”€â”€ mlruns
â”‚   â”œâ”€â”€ .trash
â”‚   â”œâ”€â”€ 0
â”‚   â”‚   â””â”€â”€ meta.yaml
â”‚   â””â”€â”€ 655008300926127301
â”‚       â”œâ”€â”€ 02bcfd2f006648e991bb8cf920ff8455
â”‚       â”œâ”€â”€ 064d792a000f40edad55a9dcb346a3f6
â”‚       â”œâ”€â”€ 47a848b640f44cb6b9e6ac9866e004a8
â”‚       â”œâ”€â”€ 7af705d3d8dd4963a59af661c7a7473e
â”‚       â”œâ”€â”€ 94102186f16441e4b31349332486433a
â”‚       â”œâ”€â”€ a74ea3ad2a054addb967c8dbf7e42215
â”‚       â”œâ”€â”€ meta.yaml
â”‚       â”œâ”€â”€ models
â”‚       â”‚   â”œâ”€â”€ m-40ba706ee0594f82b568ea241e24212f
â”‚       â”‚   â”œâ”€â”€ m-881c86506c564aa2a957c4437ab4cdd9
â”‚       â”‚   â”œâ”€â”€ m-9ebc73d55674408097573767ca7b8c64
â”‚       â”‚   â”œâ”€â”€ m-bfa13ba755d34080afbc1b49cea836de
â”‚       â”‚   â”œâ”€â”€ m-dc21ce9a2d684b13bceecece01574d95
â”‚       â”‚   â””â”€â”€ m-dea5154b647b4290afece9e0de2d46e0
â”‚       â””â”€â”€ 02bcfd2f006648e991bb8cf920ff8455
â”‚           â”œâ”€â”€ artifacts
â”‚           â”œâ”€â”€ metrics
â”‚           â”œâ”€â”€ outputs
â”‚           â”œâ”€â”€ params
â”‚           â””â”€â”€ tags
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ iris_classifier.joblib
â”‚   â”œâ”€â”€ iris_pipeline.joblib
â”‚   â””â”€â”€ iris_model.joblib
â”œâ”€â”€ monitoring
â”‚   â”œâ”€â”€ cm_logistic_regression.png
â”‚   â”œâ”€â”€ cm_random_forest.png
â”‚   â”œâ”€â”€ cm_svm.png
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ outputs
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ decision_boundaries.png
â”‚   â”œâ”€â”€ feature_distribution.png
â”‚   â””â”€â”€ pair_plot.png
â”œâ”€â”€ sample_data
â”‚   â”œâ”€â”€ .ipynb_checkpoints
â”‚   â”œâ”€â”€ anscombe.json
â”‚   â”œâ”€â”€ california_housing_test.csv
â”‚   â”œâ”€â”€ california_housing_train.csv
â”‚   â”œâ”€â”€ mnist_test.csv
â”‚   â”œâ”€â”€ mnist_train_small.csv
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ tests
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ correlation_heatmap.png
â”œâ”€â”€ decision_boundaries.png
â”œâ”€â”€ feature_distribution.png
â”œâ”€â”€ folder_structure.txt
â”œâ”€â”€ iris_model.joblib
â”œâ”€â”€ iris_pipeline.joblib
â””â”€â”€ pair_plot.png

```
## ğŸš¦ How to Run

1. **Install requirements**:
   ```bash
   pip install -r requirements.txt
Run Streamlit app:
  ```bash
streamlit run app.py
```

ğŸ§¾ Key Features
Interactive UI to upload data

Model training with user-selected hyperparameters

Real-time predictions

Beautiful metrics and visualizations

ğŸ‰ Final Thoughts
This wraps up my 30-day ML project challenge. This project ties everything together â€” theory, practice, and deployment!

ğŸ“¬ Connect with Me
LinkedIn: [www.linkedin.com/in/shadabur-rahaman-1b5703249]

GitHub: [https://github.com/Shadabur-Rahaman/30-days-ml-projects/blob/main/]

