# ğŸ§  Explainable AI (XAI): SHAP, LIME, Grad-CAM

This project demonstrates the use of **Explainable AI (XAI)** techniques to understand predictions made by machine learning models, both for **tabular** and **image** data.

## ğŸ“Œ Techniques Covered
- **SHAP**: Global & local interpretability using SHapley values
- **LIME**: Local interpretable model-agnostic explanations
- **Grad-CAM**: Visual explanation for CNN decisions
- **Partial Dependence Plot (PDP)**

---

## ğŸ“ Project Structure

```bash
Day22_ExplainableAI_CNN_and_Tabular/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ heart.csv                              # Tabular dataset for heart disease classification
â”‚   â””â”€â”€ test_samples/                          # Sample images used for CNN explainability
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ day_22_explainable_ai.ipynb            # Main notebook (image + tabular explainability)
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ gradcam_output.png                     # Grad-CAM visualization
â”‚   â”œâ”€â”€ lime_explanation.png                   # LIME explanation over heart data
â”‚   â”œâ”€â”€ lime_correct.png                       # LIME explanation on correctly predicted instance
â”‚   â”œâ”€â”€ lime_incorrect.png                     # LIME explanation on incorrectly predicted instance
â”‚   â”œâ”€â”€ shap_feature_importance.png            # SHAP feature importance bar plot
â”‚   â”œâ”€â”€ shap_waterfall_plot.png                # SHAP waterfall for a single prediction
â”‚   â”œâ”€â”€ shap_dependence_plot.png               # SHAP dependence between features
â”‚   â”œâ”€â”€ shap_decision_plot.png                 # SHAP decision path visualization
â”‚   â””â”€â”€ pdp_thalach.png                        # Partial Dependence Plot for "thalach" feature
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model_loader.py                        # Loads pretrained models (CNN or tabular)
â”‚   â”œâ”€â”€ explainability_tools.py                # Grad-CAM, SHAP, LIME functions
â”‚   â””â”€â”€ image_utils.py                         # Image loading, preprocessing, plotting
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ lime_explainer.joblib                  # Saved LIME explainer object
â”‚   â”œâ”€â”€ shap_explainer.joblib                  # Saved SHAP TreeExplainer object
â”‚   â”œâ”€â”€ lime_config.json                       # LIME configuration details
â”‚   â”œâ”€â”€ shap_data.npy                          # SHAP input data
â”‚   â”œâ”€â”€ shap_values.npy                        # SHAP value array
â”‚   â”œâ”€â”€ shap_base_values.npy                   # SHAP base values
â”‚   â””â”€â”€ shap_feature_names.json                # JSON list of feature names used in SHAP
â”‚
â”œâ”€â”€ requirements.txt                           # Python packages required
â”œâ”€â”€ .gitignore                                 # Git ignored files
â””â”€â”€ README.md                                  # Project summary and usage
---

## ğŸ“Š Visualizations

| SHAP Feature Importance | SHAP Decision Plot |
|-------------------------|---------------------|
| ![](images/shap_feature_importance.png) | ![](images/shap_decision_plot.png) |

| LIME Explanation | Grad-CAM Overlay |
|------------------|------------------|
| ![](images/lime_correct.png) | *(Add image if CNN used)* |

---

## ğŸ§ª How to Run

```bash
# Clone repo and navigate
git clone https://github.com/your-username/Day22_Explainable_AI.git
cd Day22_Explainable_AI

# Install dependencies
pip install -r requirements.txt

# Run notebook
jupyter notebook notebooks/Day22_Explainable_AI.ipynb
ğŸ§  Learnings
Understand how SHAP assigns responsibility to features.

Use LIME to visualize feature perturbation and impact.

Generate Grad-CAM overlays for CNN image classification.

Build explainable pipelines for real-world tabular or vision-based ML tasks.

ğŸš€ Future Scope
Use Anchors or Counterfactual Explanations.

Add Integrated Gradients for CNNs.

Extend to real-time XAI in production dashboards.

ğŸ“… Part of 30 Days of ML Projects
This is Day 22 of my #30DaysMLProjects challenge.

Stay tuned for Day 23: Anomaly Detection â€“ Detect anomalies in network or transaction data ğŸ”¥
