# ğŸ¤– Chatbot using Seq2Seq (Day 20 - #30DaysMLProjects)

This project implements a basic **chatbot** using a **Sequence-to-Sequence (Seq2Seq)** model with an **Encoder-Decoder LSTM** architecture. It demonstrates how deep learning can be used for conversational AI.

---

## ğŸ“Œ Features
- Text preprocessing (cleaning, tokenization, padding)
- Seq2Seq architecture using LSTMs
- Teacher forcing for better training
- Response generation using greedy decoding

---

## ğŸ“ Project Structure
```bash
Day20_Chatbot_Seq2Seq/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Day_20_Chatbot_Seq2Seq_Model.ipynb   # Cleaned final notebook
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py                # Tokenization, padding, cleaning
â”‚   â”œâ”€â”€ model_seq2seq.py                     # Encoder-Decoder LSTM architecture
â”‚   â”œâ”€â”€ inference.py                         # Code to generate responses
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ sample_conversations.txt             # Example chatbot conversations
â”‚   â””â”€â”€ training_plot.png                    # Loss vs Epoch plot
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore


---

## ğŸš€ How to Run

1. Clone the repo:

git clone https://github.com/YourUsername/30-days-ml-projects.git
cd Day20_Chatbot_Seq2Seq
Install dependencies:

pip install -r requirements.txt
Run training script (or use Jupyter notebook):


python src/model_seq2seq.py
Chat with your bot:


python src/inference.py
ğŸ›  Libraries Used
TensorFlow / Keras

Numpy

NLTK

Matplotlib

ğŸ“¦ Output
sample_conversations.txt: Responses generated by chatbot

training_plot.png: Training loss visualization

ğŸ“š References
Seq2Seq with Keras (Chatbot example)

TensorFlow Encoder-Decoder Tutorials

ğŸ“Œ Coming Up Next
Day 21: End-to-End Image Captioning using CNN + RNN
Stay tuned! ğŸš€
